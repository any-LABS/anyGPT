[metadata]
name = anyGPT
version = 0.1.0
author = Miguel Alonso Jr
author_email = drmiguelalonsojr@gmail.com
maintainer = Chad Dettmering
maintainer_email = chad.dettmering@gmail.com
description = A general purpose library for training any type of GPT model. Support for gpt-1, gpt-2, and gpt-3 models.
long_description = file: docs/README.md
long_description_content_type = text/markdown; charset=UTF-8; variant=GFM
keywords = ai, ml, rl, gpt, llm, rlhf
license = MIT
classifiers = 
    Development Status :: 4 - Beta
    Intended Audience :: Developers
    License :: OSI Approved :: MIT License
    Programming Language :: Python :: 3.10
    Topic :: Scientific/Engineering :: Artificial Intelligence
    Typing :: Typed

[options]
package_dir=
    =src
packages=find:
install_requires =
    torch >= 2.0.0
    numpy
    transformers
    datasets
    tiktoken
    wandb
    tqdm
    PyYAML
    lightning
    tensorboard
    fastapi
    uvicorn
    gymnasium
    validators


[options.packages.find]
where=src

[options.entry_points]
console_scripts=
    anygpt-prepare-data = anyGPT.data.prepare_data:main
    anygpt-pretrain = anyGPT.training.pretrain:main
    anygpt-rl-train = anyGPT.training.rl_train:main
    anygpt-run = anyGPT.inference.run:main
    anygpt-serve = anyGPT.service.app:main

[options.extras_require]
dev =
    black==23.3.0
    pytest
    pytest-cov
    pytest-sugar
    build
    twine
    httpx

[flake8]
max-line-length=120
ignore =
    # Black tends to introduce things flake8 doesn't like, such as "line break before binary operator"
    # or whitespace before ':'. Rather than fight with black, just ignore these for now.
    W503, E203,
    # flake-tidy-import adds this warning, which we don't really care about for now
    I200,